PORT=5000
NODE_ENV=development
CLIENT_URL=http://localhost:3000

# Ollama Local LLM Configuration
OLLAMA_MODEL=llama3.2
OLLAMA_HOST=http://localhost:11434
OLLAMA_TIMEOUT=30000
AI_FALLBACK=true
